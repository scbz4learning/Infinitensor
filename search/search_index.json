{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scbz's blog of learning Infinitensor 2025 Summer","text":""},{"location":"#stage-0","title":"Stage 0","text":""},{"location":"#stage-1","title":"Stage 1","text":""},{"location":"Stage_0/0-1-rustlings/","title":"rustlings","text":""},{"location":"Stage_0/0-1-rustlings/#day-01-rustlings-00-10","title":"Day 01 - rustlings 00-10","text":"<p>Selected questions</p>"},{"location":"Stage_0/0-1-rustlings/#variables","title":"Variables","text":"<ol> <li>must use <code>let</code>, type can be inferred automatically, except <code>const</code>.  </li> <li><code>const</code> must be named with a type.  </li> <li>Only var with <code>mut</code> can be mutable.  </li> <li>vars can be shadowing with a new type/ value.   </li> </ol>"},{"location":"Stage_0/0-1-rustlings/#move-semantics","title":"Move Semantics","text":"<p>Just remind: 1. One variable one ownership 2. Variable can be borrowed, but there is at most 1 mutable borrow simultaneously   </p>"},{"location":"Stage_0/0-1-rustlings/#structs","title":"Structs","text":"<ul> <li> why we need \"UnitStructs\"?  </li> </ul>"},{"location":"Stage_0/0-1-rustlings/#string-and-str","title":"<code>String</code> and <code>&amp;str</code>","text":"<ul> <li> The methods are weird... Some methods can change the type while somes are not...</li> </ul>"},{"location":"Stage_0/0-1-rustlings/#vec","title":"Vec","text":"<p><code>input.iter().map(|element| element + 1).collect()</code>, just like lambda in python.  </p>"},{"location":"Stage_0/0-1-rustlings/#modules","title":"Modules","text":"<ul> <li> Like a class without attribute members?  </li> <li>No... It is same as <code>#include</code> while class methods are defined by <code>impl</code>.  </li> </ul> <p>For the general cases:  </p> \u6982\u5ff5 C++ \u5bf9\u5e94 Rust \u5bf9\u5e94 \u7c7b\u578b\u5b9a\u4e49 <code>struct</code>, <code>class</code> <code>struct</code>, <code>enum</code> \u65b9\u6cd5 \u6210\u5458\u51fd\u6570 <code>impl</code> \u5757\u4e2d\u7684\u65b9\u6cd5 \u63a5\u53e3/\u62bd\u8c61 \u62bd\u8c61\u7c7b, \u865a\u51fd\u6570 <code>trait</code> + <code>impl</code> \u6a21\u5757/\u547d\u540d\u7a7a\u95f4 <code>namespace</code>, <code>.h</code> \u6587\u4ef6 <code>mod</code>, <code>use</code>, <code>crate</code> \u5b8f <code>#define</code>, <code>template</code> <code>macro_rules!</code>, <code>macro</code> \u53ef\u9009\u503c \u6307\u9488\u6216 <code>std::optional</code> <code>Option&lt;T&gt;</code> \u9519\u8bef\u5904\u7406 \u5f02\u5e38 (<code>try/catch</code>) <code>Result&lt;T, E&gt;</code> \u5185\u5b58\u7ba1\u7406 \u624b\u52a8\u6216\u667a\u80fd\u6307\u9488 \u6240\u6709\u6743\u7cfb\u7edf + \u751f\u547d\u5468\u671f"},{"location":"Stage_0/0-1-rustlings/#day-02-rustlings-11-13","title":"Day 02 - rustlings 11-13","text":""},{"location":"Stage_0/0-1-rustlings/#hashmaps","title":"Hashmaps","text":"<ol> <li><code>use</code> </li> <li>Create: <code>let mut map = HashMap::new();</code> </li> <li>Insert:   <ol> <li>Must exist: <code>map.insert(key, value)</code> </li> <li>Not sure: <code>map.entry(key).or_insert(value)</code> </li> </ol> </li> <li>Get: <code>map.get(key)</code> -&gt; <code>Some(value)</code> </li> <li>Loop:  <ol> <li>Readonly: <code>for (key, value) in &amp;map {}</code> </li> <li>Mutable: <code>for (key, value) in &amp;mut map {}</code> </li> <li>for keys / values only: <code>for key in map.keys()</code>, <code>for value in map.values()</code> </li> <li><code>map.iter()</code> </li> <li>Consumable iteration (move the ownership, i.e. cannot be used next time): <code>map.into_iter()</code> </li> </ol> </li> <li>Update:  <ol> <li>Must exist: <code>map.insert(key, value)</code> </li> <li>Not sure: <code>map.and_modify(key, value)</code> </li> </ol> </li> <li>Remove: <code>map.remove(key, value)</code> </li> </ol> <p><code>hashmaps2.rs</code> \u4f3c\u4e4e\u6709\u95ee\u9898\uff0c47\u52a0\u4e00\u4e2a<code>use</code>\u53ef\u4ee5\u89e3\u51b3 <pre><code>44     #[cfg(test)]\n45     mod tests {\n46         use super::*;\n47 +++     use std::iter::FromIterator;\n</code></pre></p> <p><code>hashmaps3.rs</code> is quite interesting  </p> <p>Here is my implementation, which is obviously stupid...   <pre><code>scores.entry(team_1_name)\n    .and_modify(|v| {v.goals_scored += team_1_score; v.goals_conceded += team_2_score})\n    .or_insert(TeamScores{goals_scored: team_1_score, goals_conceded: team_2_score});\nscores.entry(team_2_name)\n    .and_modify(|v| {v.goals_scored += team_2_score; v.goals_conceded += team_1_score})\n    .or_insert(TeamScores{goals_scored: team_2_score, goals_conceded: team_1_score});\n</code></pre></p> <p>The solution is quite interesting: <pre><code>// Insert the default with zeros if a team doesn't exist yet.\nlet team_1 = scores.entry(team_1_name).or_default();\n// Update the values.\nteam_1.goals_scored += team_1_score;\nteam_1.goals_conceded += team_2_score;\n\n// Similarly for the second team.\nlet team_2 = scores.entry(team_2_name).or_default();\nteam_2.goals_scored += team_2_score;\nteam_2.goals_conceded += team_1_score;\n</code></pre></p> <ol> <li><code>or_default()</code> will insert a default value into hash maps when there is no such entry. The default values of some types are:      <ul> <li> \u7c7b\u578b <code>Default::default()</code> \u7684\u503c <code>u8</code> <code>0</code> <code>bool</code> <code>false</code> <code>String</code> <code>\"\"</code> <code>Vec&lt;T&gt;</code> <code>[]</code> <code>Option&lt;T&gt;</code> <code>None</code> </li> </ul> </li> <li><code>or_default</code> -&gt; <code>mut &amp;</code>, i.e. it will return a mutable reference, so changing team_1 is changing the bucket.  </li> </ol>"},{"location":"Stage_0/0-1-rustlings/#options","title":"Options","text":"<p>Just <code>Some(...)</code> and <code>None</code> </p> <p>However, the usage of <code>match</code> is appalled: <code>match</code> will move the ownership when matching! </p>"},{"location":"Stage_0/0-1-rustlings/#error-handling-results","title":"Error Handling (Results)","text":"<p>1-3 and 5 are basic questions.</p>"},{"location":"Stage_0/0-1-rustlings/#errors4rs","title":"<code>errors4.rs</code>","text":"<p>Understanding: 1. <code>#[derive(...)]</code> is a <code>macro</code>, using it can add common traits to structs and enums. 2. <code>#[derive(PartialEq, Debug)]</code> add traits <code>PartialEq</code> and <code>Debug</code> to the struct <code>PositiveNonzeroInteger</code>, so that:     1. <code>PartialEq</code> can deal with equality test without changing types of both sides to be exactly same. This is wrong! The types of sides of equality test must be the same. However, it is the trait that enables the equality test to make sense. Without it, there is no defination in the struct and its implementation for , !.          -  For example, assert_eq!(PositiveNonzeroInteger::new(10), Ok(PositiveNonzeroInteger(10)));  will not yield an error, although the left is a struct and the right is the struct wrapped into an result. They are in the same types. The new impl returns an result as well!  Remember, both sides must be in the same type. However, without PartialEq, the == cannot be recognised.         -  Comparing PositiveNonzeroInteger::new(10) &gt;= PositiveNonzeroInteger::new(8) is not applicable here, as PartialEq only deal with equality test, while the comparisons are handled by the trait*s PartialOrd (may fail and return None Best effort. If not compariable, return None. e.g. comparing any float number with <code>NaN</code>) or Ord (must use with PartialEq and PartialOrd. Will never fail but may be over-compared Will always give a boolean result or the program will crash. e.g. we may not need a real comparison for a float number and a string We cannot compare a float with a string, the both sides must be in the same type. e.g. comparing any float number with <code>NaN</code> in <code>Ord</code> will crash the program as there is not such trait applied, which is because this camparison is logically nonsense).      2. <code>Debug</code> enables <code>{:?}</code> and <code>{:#?}</code> in <code>println!</code> 3. <code>Self</code> means the *impl <code>PositiveNonzeroInteger</code>. (Nothing special here, just like <code>self</code> in python.)  </p> <p>For implementation, <code>if value &gt;/==</code> is trivial: <pre><code>if value &gt; 0 {\n    // value is i64 and we need u64 inside the struct\n    // use `as` to cast the type\n    Ok(PositiveNonzeroInteger(value as u64)) \n} else if value == 0 {\n    Err(CreationError::Zero)\n} else {\n    Err(CreationError::Negative)\n}\n</code></pre> Although complicated, there is no issue. <code>match</code> is useful as well, the comparison can be handled in braches: <pre><code>match value {\n    n if n &gt; 0 =&gt; Ok(PositiveNonzeroInteger(n as u64)), // handle the postive part\n    0 =&gt; Err(CreationError::Zero),\n    _ =&gt; Err(CreationError::Negative),\n}\n</code></pre> However, there is a fancy and idiomatic (\u5730\u9053\u7684, \u4e60\u8bed\u7684, \u6210\u8bed\u7684, \u5408\u4e4e\u8bed\u8a00\u4e60\u60ef\u7684) method, given in the sample solution: <pre><code>use std::cmp::Ordering;\nmatch value.cmp(&amp;0) {\n    Ordering::Less =&gt; Err(CreationError::Negative),\n    Ordering::Equal =&gt; Err(CreationError::Zero),\n    Ordering::Greater =&gt; Ok(Self(value as u64)),\n}\n</code></pre> <code>impl Ord</code> for <code>i64</code> gives <code>fn cmp</code>, the return value is of type <code>Ording</code>, which is a enum with only 3 values: <pre><code>#[repr(i8)]\npub enum Ordering {\n    Less = -1,\n    Equal = 0,\n    Greater = 1,\n}\n</code></pre></p>"},{"location":"Stage_0/0-1-rustlings/#errors6rs","title":"<code>errors6.rs</code>","text":""},{"location":"Stage_0/0-1-rustlings/#now-how-can-we-handle-errors","title":"Now how can we handle errors?","text":"<ol> <li>We can (obviously we do not want) let it crash, by compiler errors, or <code>panic</code> (just like <code>assert</code> in python)  </li> <li>Just like <code>try</code> and <code>except</code> in python, we can handle the known issue we might have and let the program continues. We use <code>Result&lt;T, E&gt;</code> syntax in rust with reasons in <code>E</code>, like <code>TypeError</code> in python.  <ol> <li>For catch-all. Sometimes we do not care about why, just like <code>except</code> without specific error in python. we can use <code>Box&lt;dyn Error&gt;</code> in <code>errors5.rs</code> or just self-buit message like <code>Err(format!(\"Empty names aren't allowed\"))</code> in <code>errors1.rs</code>. However, these are not standarised for re-use.  </li> <li>Preferably, we define the error types in <code>enum</code> (now like C) and then map the error for readability.  </li> </ol> </li> </ol> <p>Here, we first create the enum if error types</p> <pre><code>use std::num::ParseIntError;\n\n#[derive(PartialEq, Debug)]\nenum CreationError {\n    Negative,\n    Zero,\n}\n</code></pre> <p>Then, we need an impl to parse the error - just like in python, to give definition of the process that <code>5 + \"1\"</code> will raise <code>TypeError</code>. But *impl*s cannot exist themself, we need a enum to place them:  </p> <pre><code>#[derive(PartialEq, Debug)]\nenum ParsePosNonzeroError {\n    Creation(CreationError),\n    ParseInt(ParseIntError),\n}\n\nimpl ParsePosNonzeroError {\n    fn from_creation(err: CreationError) -&gt; Self {\n        Self::Creation(err)\n    }\n\n    // TODO: Add another error conversion function here.\n    fn from_parse_int(err: ParseIntError) -&gt; Self {\n        Self::ParseInt(err)\n    }\n}\n</code></pre> <p>The enum <code>ParsePosNonzeroError</code> gives almost nothing, just wrap the enum <code>CreationError</code> and <code>ParseIntError</code> (using from std) again. However, with their helps, we can now give impl to translate them. Note that there is noway to give one enum only, as the <code>CreationError</code> and <code>ParseIntError</code> are handlers where <code>ParsePosNonzeroError</code> is the process. </p> <p>The impl will take the handler in as an argument and then return an error of its *variant*s.</p>"},{"location":"Stage_0/0-1-rustlings/#creationerror-internal","title":"<code>CreationError</code> internal","text":"<p>Lets see the process of  <pre><code>#[test]\nfn test_zero() {\n    assert_eq!(\n        PositiveNonzeroInteger::parse(\"0\"),\n        Err(ParsePosNonzeroError::Creation(CreationError::Zero)),\n    );\n}\n</code></pre></p> <p>The <code>\"0\"</code> is parsed by <code>PositiveNonzeroInteger::parse()</code></p> <pre><code>impl PositiveNonzeroInteger {\n    fn new(value: i64) -&gt; Result&lt;Self, CreationError&gt; {\n        match value {\n            x if x &lt; 0 =&gt; Err(CreationError::Negative),\n            0 =&gt; Err(CreationError::Zero),\n            x =&gt; Ok(Self(x as u64)),\n        }\n    }\n\n    fn parse(s: &amp;str) -&gt; Result&lt;Self, ParsePosNonzeroError&gt; {\n        // TODO: change this to return an appropriate error instead of panicking\n        // when `parse()` returns an error.\n        let x: i64 = s.parse().unwrap()...;\n        Self::new(x).map_err(ParsePosNonzeroError::from_creation)\n    }\n}\n</code></pre> <p>First, the <code>fn parse</code> deal with <code>\"0\".parse()</code>. <code>str.parse()</code> is to parse any <code>&amp;str</code> into another type, wrapped by <code>Result &lt;T,E&gt;</code>, which is so general, so the type must be known for compiler. For example  </p> <pre><code>let x = \"0\".parse(); // Error, the compiler does not know the type of x\nlet x:i32 = \"0\".parse(); // Error, the return value of `parse()` is wrapped in `Result &lt;T, E&gt;` \nuse std::num::ParseIntError;\nlet x:Result&lt;i32, ParseIntError&gt; = \"0\".parse(); // Works, but rare. x = Ok(0)\n\nlet x:i32 = \"0\".parse().unwrap(); // Good, the compiler infer \"0\".parse() to be i32\nlet x = \"0\".parse::&lt;i32&gt;().unwrap(); // Good, the compiler infer x to be i32, as the type of \"0\".parse() is specified by generic syntax\n</code></pre> <p>So now, we ignore the error handling <code>...</code> after <code>s.parse().unwrap()</code> and get <code>x:i64=0</code>. We now pass the <code>x</code> to <code>Self::new(x)</code>, which is <code>PositiveNonzeroInteger:new(x)</code>. The <code>new()</code> does <code>match</code> and find return <code>Err(CreationError::Zero)</code>. Now, we handle the error: <code>Err(CreationError::Zero).map_err(ParsePosNonzeroError::from_creation)</code>. From the basics, the <code>map_err</code> just map all errors (here is <code>Err(CreationError::Zero)</code>) to a specific error <code>Err&lt;e&gt;</code>, where e is returned by a process (here is <code>ParsePosNonzeroError::from_creation</code>). The process <code>ParsePosNonzeroError::from_creation</code> is a <code>impl fn</code>, which is just like function pointer in C. The process <code>ParsePosNonzeroError::from_creation</code> get <code>CreationError::Zero</code> as an argument and find the type is correct (as the parameter is defined as <code>err: CreationError</code>). Now, it will give the return value as <code>e = ParsePosNonzeroError::Creation(CreationError::Zero)</code>. The <code>map_err()</code> will wrap the <code>e</code> into an <code>Err&lt;&gt;</code>, therefore, the final result is <code>Err(ParsePosNonzeroError::Creation(CreationError::Zero))</code>, which is correct!  </p>"},{"location":"Stage_0/0-1-rustlings/#fix-to-do","title":"Fix <code>to do</code>","text":"<p>Now, we need to think about what we ignore. If <code>&amp;str.parse()</code> fails, the program will crash when <code>unwrap()</code>. To deal with this, we can match the result:  </p> <pre><code>// this is how we init Result&lt;T,E&gt; var\nlet res = s.parse::&lt;i64&gt;();\nmatch res {\n    Ok(v) =&gt; Self::new(v).map_err(ParsePosNonzeroError::from_creation),\n    Err(e) =&gt; Err(e).map_err(ParsePosNonzeroError::from_parse_int)\n}\n</code></pre> <p>However, a better way is:</p> <pre><code>fn parse(s: &amp;str) -&gt; Result&lt;Self, ParsePosNonzeroError&gt; {\n    // Return an appropriate error instead of panicking when `parse()`\n    // returns an error.\n    let x: i64 = s.parse().map_err(ParsePosNonzeroError::from_parse_int)?;\n    Self::new(x).map_err(ParsePosNonzeroError::from_creation)\n}\n</code></pre> <p>If <code>s.parse()</code> is successful, then value inside <code>Ok()</code> is extracted and assigned to <code>x</code>; Otherwise, it raises <code>Err(ParseIntError)</code>. Then  <code>Err(ParseIntError)</code> will be mapped by the process of <code>ParsePosNonzeroError::from_parse_int</code>, from <code>Err(ParseIntError)</code> to <code>Err(Self::ParseInt(err))</code>. Therefore, the final result of this line should be either      - <code>x</code> is assigned to some <code>i64</code> and then use <code>new()</code> to find the creation error,     - or return <code>Err(ParsePosNonzeroError::ParseInt(ParseIntError))</code>.   </p>"},{"location":"Stage_0/0-1-rustlings/#a-standarised-way-from-trait","title":"A Standarised Way - <code>From</code> Trait","text":"<p>This is actually a manual built <code>From</code> trait. A better way is:  </p> <pre><code>#[derive(PartialEq, Debug)]\nenum ParsePosNonzeroError {\n    Creation(CreationError),\n    ParseInt(ParseIntError),\n}\n\n// \u6807\u51c6\u5316\u7684 From \u5b9e\u73b0\nimpl From&lt;CreationError&gt; for ParsePosNonzeroError {\n    fn from(err: CreationError) -&gt; Self {\n        ParsePosNonzeroError::Creation(err)\n    }\n}\n\nimpl From&lt;ParseIntError&gt; for ParsePosNonzeroError {\n    fn from(err: ParseIntError) -&gt; Self {\n        ParsePosNonzeroError::ParseInt(err)\n    }\n}\n</code></pre> <p>Now, the creation error is handled in a standarised way. We can now simplify the <code>fn parse()</code>:  </p> <pre><code>fn parse(s: &amp;str) -&gt; Result&lt;Self, ParsePosNonzeroError&gt; {\n    let x: i64 = s.parse()?; // the mapping is handled via `From` automatically\n    let v = Self::new(x)?; // the mapping is handled via `From` automatically\n    Ok(v) // The v is now unwrapped if successful. To make return value in the same type, wrap it again.\n}\n</code></pre>"},{"location":"Stage_0/0-1-rustlings/#map_err-internal","title":"<code>map_err</code> Internal","text":"<p>What is <code>map_err</code>? What are the parameters?</p> <p><code>pub fn map_err&lt;F, O&gt;(self, op: O) -&gt; Result&lt;T, F&gt;</code> where <code>O: FnOnce(E) -&gt; F,</code> </p> <p>Maps a Result to Result by applying a function to a contained Err value, leaving an Ok value untouched.   <p>This function can be used to pass through a successful result while handling an error.</p> <p>Examples  </p> <pre><code>fn stringify(x: u32) -&gt; String { format!(\"error code: {x}\") }  \n\nlet x: Result&lt;u32, u32&gt; = Ok(2);  \nassert_eq!(x.map_err(stringify), Ok(2));  \n\nlet x: Result&lt;u32, u32&gt; = Err(13);  \nassert_eq!(x.map_err(stringify), Err(\"error code: 13\".to_string()));  \n</code></pre> <p>Given <code>a:&lt;Result&lt;T,E&gt;&gt;</code>, <code>a.map_err(Op)</code> is equivlent to a <code>match</code> statement:   </p> <pre><code>match a {\n    Ok(v) =&gt; Ok(v), // leave the T part not touched\n    Err(e) =&gt; Err(Op(e)),\n};\n</code></pre> <p>where <code>Op: FnOnce</code> is a one-time (means the ownership will be moved after the first call -  we do not want to touch an error twice) function pointer or closure pointer. <code>Op(e)</code> will return another <code>e</code>, which is why it is called <code>map_err()</code>.   </p>"},{"location":"Stage_0/0-1-rustlings/#generic","title":"Generic","text":""},{"location":"Stage_0/0-1-rustlings/#traits","title":"Traits","text":"<pre><code>fn some_func(item: impl SomeTrait + OtherTrait) -&gt; bool {\n    item.some_function() &amp;&amp; item.other_function()\n}\n</code></pre> <p>If your function is generic over a trait but you don't mind the specific type, you can simplify the function declaration using impl Trait as the type of the argument.</p> \u7279\u6027 / Feature \u9759\u6001\u5206\u53d1\uff08\u6cdb\u578b\uff09 / Static Dispatch (Generics) \u52a8\u6001\u5206\u53d1\uff08<code>dyn Trait</code>\uff09 / Dynamic Dispatch (<code>dyn Trait</code>) \u7c7b\u578b\u5df2\u77e5\u65f6\u95f4 / Type Known \u7f16\u8bd1\u65f6 / Compile-time \u8fd0\u884c\u65f6 / Runtime \u6027\u80fd / Performance \u66f4\u5feb\uff0c\u53ef\u5185\u8054 / Faster, can be inlined \u7a0d\u6162\uff08vtable \u67e5\u8be2\uff09 / Slightly slower (vtable lookup) \u4e8c\u8fdb\u5236\u5927\u5c0f / Binary Size \u53ef\u80fd\u53d8\u5927 / May increase \u66f4\u5c0f\uff08\u5355\u4efd\u4ee3\u7801\uff09 / Smaller (single code copy) \u7075\u6d3b\u6027 / Flexibility \u4e0d\u80fd\u6df7\u591a\u79cd\u7c7b\u578b / Cannot mix multiple concrete types \u53ef\u4ee5\u5b58\u653e\u591a\u79cd\u7c7b\u578b / Can store multiple different types \u5e38\u89c1\u573a\u666f / Common Use Cases \u6570\u503c\u8ba1\u7b97\u3001\u6027\u80fd\u654f\u611f\u4ee3\u7801 / Numeric computation, performance-critical code \u63d2\u4ef6\u7cfb\u7edf\u3001GUI \u7ec4\u4ef6\u3001\u591a\u6001\u5bb9\u5668 / Plugin systems, GUI components, heterogeneous containers \u7279\u6027 / Feature \u6cdb\u578b\u53c2\u6570 / Generic Parameter \u5173\u8054\u7c7b\u578b / Associated Type \u5b9a\u4e49\u4f4d\u7f6e / Definition Location <code>trait MyIterator&lt;T&gt; { fn next(&amp;mut self) -&gt; Option&lt;T&gt;; }</code> <code>trait MyIterator { type Item; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;; }</code> \u7c7b\u578b\u7ed1\u5b9a\u65f6\u95f4 / Type Binding Time \u4f7f\u7528\u65f6\u6307\u5b9a / At usage: <code>fn foo&lt;I: MyIterator&lt;i32&gt;&gt;(iter: I)</code> \u5b9e\u73b0\u65f6\u6307\u5b9a / At implementation: <code>impl MyIterator for Counter { type Item = i32; ... }</code> \u7075\u6d3b\u6027 / Flexibility \u540c\u4e00\u7c7b\u578b\u53ef\u591a\u6b21\u5b9e\u73b0\u4e0d\u540c\u7248\u672c / Same type can have multiple versions \u4e00\u4e2a\u7c7b\u578b\u53ea\u80fd\u6709\u4e00\u4e2a\u56fa\u5b9a\u7248\u672c / One fixed version per type \u53ef\u8bfb\u6027 / Readability \u591a\u4e2a trait \u4f1a\u5f88\u5570\u55e6 / Verbose with multiple traits \u66f4\u7b80\u6d01 / Cleaner syntax \u793a\u4f8b / Example <code>impl MyIterator&lt;i32&gt; for Counter { ... }</code> <code>impl MyIterator for Counter { type Item = i32; ... }</code>"},{"location":"Stage_0/0-1-rustlings/#lifetimes","title":"Lifetimes","text":"<p>If a member in struct is a reference, it must explicitly specified with lifetime!</p>"},{"location":"Stage_0/0-1-rustlings/#tests","title":"Tests","text":"<pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn correct_width_and_height() {\n        // TODO: This test should check if the rectangle has the size that we\n        // pass to its constructor.\n        let rect = Rectangle::new(10, 20);\n        assert_eq!(rect.width, 10); // Check width\n        assert_eq!(rect.height, 20); // Check height\n    }\n\n    // TODO: This test should check if the program panics when we try to create\n    // a rectangle with negative width.\n    #[test]\n    #[should_panic]\n    fn negative_width() {\n        let _rect = Rectangle::new(-10, 10);\n    }\n}\n</code></pre>"},{"location":"Stage_0/0-1-rustlings/#day-03","title":"Day 03","text":"<p>I'm lazy...</p>"},{"location":"Stage_0/0-1-rustlings/#day-04","title":"Day 04","text":""},{"location":"Stage_0/0-1-rustlings/#closure","title":"Closure","text":"<p>In the Rust book, closure is introduced before iterators. Therefore, I would like to first take a look of it.   </p>"},{"location":"Stage_0/0-1-rustlings/#is-closure-a-function","title":"Is closure a function?","text":"<p>Chatgpt tells me that the closure is not as same as function: <pre><code>let add_one_v2 = |x: i32| -&gt; i32 { x + 1 };\n</code></pre></p> <p>Does it move the value of closure to a function, so we now have a named function instead of an anonymous closure? No! Closure is a anonymous struct with trait, while <code>fn</code> is a type already.</p> <p>Lets take a test</p> <pre><code>fn print_type_of&lt;T&gt;(_: &amp;T) {\n    println!(\"{}\", std::any::type_name::&lt;T&gt;());\n}\n\nfn add_fn(x: i32) -&gt; i32 { x + 1 }\n\nfn main() {\n    let add_closure = |x: i32| -&gt; i32 { x + 1 };\n\n    print_type_of(&amp;add_fn);\n    print_type_of(&amp;add_closure);\n}\n</code></pre> <pre><code>playground::add_fn\nplayground::main::{{closure}}\n</code></pre>"},{"location":"Stage_0/0-1-rustlings/#difference-between-closures-and-functions","title":"Difference between closures and functions","text":"<p>The most important one is closure can capture other vars! </p> <p>In function, one must declare the parameters before using, while in closure, one might add more known variables into process.</p> <pre><code>let factor = 10;\nlet multiply_by_factor = |x: i32| x * factor;\n</code></pre> <p>There is no need to add <code>factor</code> in <code>| |</code>, and compile smoothly.</p> <p>Also, it is not same implementation to the version with 2 params:</p> <pre><code>let multiply = |x: i32, y: i32| x * y;  \n\nprintln!(\"{}\", multiply_by_factor(5)); // the factor is capture automatically. It will always be that factor.  \nprintln!(\"{}\", multiply(5, factor)); // the multiplier can be changed now, however, it must be passed in all the time.  \n</code></pre> <p>\u8865\u5145\u6355\u83b7\u65b9\u5f0f\u662f\u81ea\u52a8\u63a8\u65ad \u7f16\u8bd1\u5668\u4f1a\u4e3a\u7b2c\u4e00\u4e2a\u95ed\u5305\u751f\u6210\u4e00\u4e2a\u5e26\u5b57\u6bb5 factor \u7684\u7ed3\u6784\u4f53\uff0c\u800c\u7b2c\u4e8c\u4e2a\u95ed\u5305\u662f\u7a7a\u7ed3\u6784\u4f53  </p>"},{"location":"Stage_0/0-1-rustlings/#three-closures","title":"Three Closures","text":"<p>As said closures are anonymous structs with trait, and there is actually 3 type of traits: 1. <code>Fn</code>: capture environments as <code>&amp;T</code> - environments are immutable. 2. <code>FnMut</code>: capture environments as <code>&amp;mut T</code>, environments are mutated. 3. <code>FnOnce</code>: capture environments as <code>T</code> - environments are moved, and thus the closure can be used once only.  </p> <p>|\u53c2\u6570\u5217\u8868| \u91cc\u7684\u662f\u8c03\u7528\u65f6\u7684\u503c\uff0c\u4e0d\u53d7\u95ed\u5305\u6355\u83b7\u65b9\u5f0f\u5f71\u54cd\u3002 \u6355\u83b7\u65b9\u5f0f\u53ea\u548c\u95ed\u5305\u7528\u5230\u7684\u5916\u90e8\u53d8\u91cf\u6709\u5173\uff08\u6bd4\u5982 factor\uff09\u3002  </p>"},{"location":"Stage_0/0-1-rustlings/#iterators","title":"Iterators","text":"<p>There are three common methods which can create iterators from a collection:</p> <ul> <li>iter(), which iterates over &amp;T.</li> <li>iter_mut(), which iterates over &amp;mut T.</li> <li>into_iter(), which iterates over T.</li> </ul>"},{"location":"Stage_0/0-1-rustlings/#iterators3rs-short-circuiting-in-collect","title":"<code>iterators3.rs</code> - short-circuiting in <code>collect()</code>","text":"<pre><code>fn divide(a: i64, b: i64) -&gt; Result&lt;i64, DivisionError&gt; {...};\n\n// TODO: Add the correct return type and complete the function body.\n// Desired output: `[Ok(1), Ok(11), Ok(1426), Ok(3)]`\nfn list_of_results() -&gt; Vec&lt;Result&lt;i64, DivisionError&gt;&gt; {\n    let numbers = [27, 297, 38502, 81];\n    numbers.into_iter().map(|n| divide(*n, 27)).collect::&lt;Vec&lt;Result&lt;i64, DivisionError&gt;&gt;&gt;()\n}\n</code></pre> <p>For a normal loop method, we need to: + changed numbers into iterator, + for each iterator, dereference it and match it to unwrap or return Err, + Other wise return <code>Ok&lt;Vec&lt;i64&gt;&gt;</code>.  </p> <p>However, <code>collect()</code> can do this job for us. It will change the type to what we want, and return the first error, which is called short-circuiting. To use this feature, the struct must have the trait <code>FromIterator</code>:</p> <pre><code>std::iter\nTrait FromIteratorCopy item path\n\npub trait FromIterator&lt;A&gt;: Sized {\n    // Required method\n    fn from_iter&lt;T&gt;(iter: T) -&gt; Self\n       where T: IntoIterator&lt;Item = A&gt;;\n}\n</code></pre> <p>Conversion from an Iterator.</p> <p>By implementing FromIterator for a type, you define how it will be created from an iterator. This is common for types which describe a collection of some kind.</p> <p>If you want to create a collection from the contents of an iterator, the <code>Iterator::collect()</code> method is preferred. However, when you need to specify the container type, FromIterator::from_iter() can be more readable than using a turbofish (e.g. <code>::&lt;Vec&lt;_&gt;&gt;()</code>). See the <code>Iterator::collect()</code> documentation for more examples of its use. </p>"},{"location":"Stage_0/0-1-rustlings/#into_iter-return-integer","title":"<code>into_iter()</code> - return <code>&lt;&amp;integer&gt;</code>","text":"<p><code>numbers.into_iter().map(|n| divide(*n, 27)).collect::&lt;Vec&lt;Result&lt;i64, DivisionError&gt;&gt;&gt;()</code></p> <p>must be <code>divide(*n, 27)</code></p>"},{"location":"Stage_0/0-1-rustlings/#iterators3rs","title":"<code>iterators3.rs</code>","text":"<ol> <li><code>hashmap.values()</code> or <code>hashmap.keys()</code> returns iterators, there is no <code>hashmap.values().iter()</code> or <code>hashmap.keys()</code> </li> <li>return value of <code>hashmap.values()</code> or <code>hashmap.keys()</code> is reference! One must dereference it to use the values.  </li> <li>the closure will add another reference to the value, so one must add <code>&amp;&amp;</code> in the closure parameter!  <ul> <li>the reason why <code>(2..=num).fold(1, |acc, x| acc * x)</code> is allows is because: <code>+</code> can dereference the value automatically!  </li> <li>it is safer to use <code>|acc, &amp;&amp;x| x</code> rather than <code>|acc, x| **x</code> </li> </ul> </li> <li><code>fold(init_value, |acc, x|)</code> should tell what <code>acc</code> should be mutated, and <code>acc</code> cannot be changed!     for example, <pre><code>(2..=num).fold(1, |acc, x| acc * x) // good, acc * x, no assignment\n(2..=num).fold(1, |acc, &amp;x| acc * x) // good, automatically dereferenced\n\nmap\n    .iter()\n    .fold(0, |count, (_k, v)| {\n        if **v == value {\n            count + 1\n        } else {\n            count\n        }\n    })                  // good, return either count or count+1\n\nmap\n    .iter()\n    .fold(0, |count, (_k, v)| {\n        if **v == value {\n            count += 1;\n        }\n        count \n    })                  // Wrong! You cannot change count!\n</code></pre></li> <li>the above <code>fold()</code> can be simplified as <code>filter()</code>, when we need to filter according to values.  </li> </ol>"},{"location":"Stage_0/0-1-rustlings/#day-05","title":"Day 05","text":""},{"location":"Stage_0/0-1-rustlings/#smart-pointers","title":"Smart Pointers","text":"<p><code>Arc</code>: Atomic operation <code>Box</code>: Dynamic allocation <code>Cow</code>: Copy-on-write: borrow when read only, owned when mutation <code>rc</code>: Counter of references  </p>"},{"location":"Stage_0/0-1-rustlings/#threads","title":"Threads","text":"\u5de5\u5177 \u4f5c\u7528 \u662f\u5426\u4fdd\u8bc1\u53ef\u53d8\u6027 \u662f\u5426\u7ebf\u7a0b\u5b89\u5168 <code>Arc&lt;T&gt;</code> \u8ba9\u591a\u4e2a\u7ebf\u7a0b\u5171\u4eab\u6570\u636e\u6240\u6709\u6743\uff08\u5f15\u7528\u8ba1\u6570\uff09 \u5426 **\u4ec5\u5f15\u7528\u8ba1\u6570**\u7ebf\u7a0b\u5b89\u5168 <code>Mutex&lt;T&gt;</code> \u5728\u540c\u4e00\u65f6\u523b\u53ea\u5141\u8bb8\u4e00\u4e2a\u7ebf\u7a0b\u8bbf\u95ee\u6570\u636e \u662f \u662f\uff08\u901a\u8fc7\u4e92\u65a5\u9501\u4fdd\u8bc1\uff09 <code>Arc&lt;Mutex&lt;T&gt;&gt;</code> \u591a\u7ebf\u7a0b\u5171\u4eab\u5e76\u5b89\u5168\u4fee\u6539\u6570\u636e \u662f \u662f"},{"location":"Stage_0/0-1-rustlings/#day-06","title":"Day 06","text":"<p>finish rustlings  </p> <ul> <li> Notes are missing</li> </ul>"},{"location":"Stage_0/0-2-learning-cxx/","title":"learning-cxx","text":""},{"location":"Stage_0/0-2-learning-cxx/#day-07","title":"Day 07","text":"<p>busy at job info searching and leetcode</p> <p>Getting familar with ai compiler project</p>"},{"location":"Stage_0/0-2-learning-cxx/#day-08","title":"Day 08","text":"<p>Starting learning-cxx project again </p>"},{"location":"Stage_0/0-2-learning-cxx/#declaration","title":"Declaration","text":"<ul> <li>\u603b\u7ed3\uff1a\u89e3\u8bfb\u590d\u6742\u58f0\u660e\u7684\u4e09\u6b65\u6cd5  <ul> <li>\u4ece\u53d8\u91cf\u540d\u5f00\u59cb\u3002  </li> <li>\u5148\u770b\u53f3\u8fb9\u518d\u770b\u5de6\u8fb9\uff0c\u62ec\u53f7\u4f18\u5148\u3002  </li> <li>\u9047\u5230\u7c7b\u578b\u4fee\u9970\u7b26\u5411\u5916\u6269\u5c55\u76f4\u5230\u5230\u8fbe\u57fa\u672c\u7c7b\u578b\u3002  </li> </ul> </li> </ul>"},{"location":"Stage_0/0-2-learning-cxx/#what-is-const-int-x-and-int-const-x","title":"What is <code>const int* x</code> and <code>int* const x</code>?","text":"<ul> <li><code>const int* x</code>: a pointer pointing to a <code>const int</code> var  <ul> <li><code>* x</code>: x is a pointer  </li> <li><code>const int</code>: pointing to <code>const int</code> </li> </ul> </li> <li><code>int* const x</code>: a <code>const</code> pointer pointing to an <code>int</code> var  <ul> <li><code>const x</code>: <code>x</code> is <code>const</code> </li> <li><code>int*</code>: the const <code>x</code> is a pointer and pointing to <code>int</code></li> </ul> </li> </ul>"},{"location":"Stage_0/0-2-learning-cxx/#parameter-passing-method","title":"Parameter passing method","text":"\u65b9\u5f0f \u8bed\u6cd5\u793a\u4f8b \u7279\u70b9 \u9002\u7528\u573a\u666f \u503c\u4f20\u9012 (Pass by Value) <code>void foo(int x)</code> **\u62f7\u8d1d**\u4e00\u4efd\u53c2\u6570\uff0c\u51fd\u6570\u5185\u90e8\u4fee\u6539\u4e0d\u5f71\u54cd\u5916\u90e8 \u5c0f\u578b\u6570\u636e\u7c7b\u578b\uff08<code>int</code>, <code>char</code>, \u5c0f\u578b\u7ed3\u6784\u4f53\u7b49\uff09\uff1b\u4fdd\u8bc1\u5916\u90e8\u6570\u636e\u5b89\u5168 \u6307\u9488\u4f20\u9012 (Pass by Pointer) <code>void foo(int* p)</code> \u4f20\u9012\u5730\u5740\uff0c\u53ef\u4fee\u6539\u5916\u90e8\u6570\u636e\uff1b\u53ef\u80fd\u4f20\u5165 <code>nullptr</code> \u9700\u8981\u53ef\u9009\uff08\u53ef\u4e3a\u7a7a\uff09\u4fee\u6539\u53c2\u6570\uff0c\u6216\u6570\u7ec4\u3001\u52a8\u6001\u5206\u914d\u5bf9\u8c61 \u5f15\u7528\u4f20\u9012 (Pass by Reference) <code>void foo(int&amp; x)</code> \u76f4\u63a5\u64cd\u4f5c\u5916\u90e8\u53d8\u91cf\uff0c\u4e0d\u80fd\u4e3a null \u5fc5\u987b\u4fee\u6539\u5916\u90e8\u6570\u636e\u4e14\u4fdd\u8bc1\u975e\u7a7a const \u5f15\u7528\u4f20\u9012 (Pass by const Reference) <code>void foo(const std::string&amp; s)</code> \u907f\u514d\u62f7\u8d1d\uff0c\u4fdd\u8bc1\u53ea\u8bfb \u5927\u5bf9\u8c61\uff08<code>std::string</code>, <code>vector</code>\u7b49\uff09\u4e14\u4e0d\u9700\u8981\u4fee\u6539 \u53f3\u503c\u5f15\u7528\u4f20\u9012 (Pass by Rvalue Reference) <code>void foo(std::string&amp;&amp; s)</code> \u7ed1\u5b9a\u4e34\u65f6\u5bf9\u8c61\uff0c\u53ef**\u79fb\u52a8\u8bed\u4e49** \u9700\u8981\u63a5\u7ba1\u4e34\u65f6\u5bf9\u8c61\u6240\u6709\u6743\uff0c\u907f\u514d\u62f7\u8d1d \u901a\u7528\u5f15\u7528 (Forwarding Reference) <code>template &lt;typename T&gt; void foo(T&amp;&amp; t)</code> \u53ef\u540c\u65f6\u7ed1\u5b9a\u5de6\u503c\u548c\u53f3\u503c \u6a21\u677f\u4e2d\u5b9e\u73b0\u5b8c\u7f8e\u8f6c\u53d1\uff08<code>std::forward</code>\uff09 \u6570\u7ec4\u4f20\u9012 <code>void foo(int arr[])</code> \u6216 <code>void foo(int* arr, size_t n)</code> \u5b9e\u9645\u662f\u6307\u9488\u4f20\u9012 \u5904\u7406\u8fde\u7eed\u5185\u5b58\u6570\u636e \u521d\u59cb\u5316\u5217\u8868\u4f20\u9012 <code>void foo(std::initializer_list&lt;int&gt; list)</code> \u652f\u6301 <code>{}</code> \u5217\u8868\u8bed\u6cd5 \u914d\u5408\u5bb9\u5668\u521d\u59cb\u5316\u53c2\u6570"},{"location":"Stage_0/0-2-learning-cxx/#what-is-the-diff-btw-lvalue-reference-and-pointer","title":"What is the diff btw lvalue reference and pointer?","text":"\u7279\u6027 \u5de6\u503c\u5f15\u7528 (<code>T&amp;</code>) \u6307\u9488 (<code>T*</code>) \u4f7f\u7528 \u76f4\u63a5\u5f53\u4f5c\u53d8\u91cf\u7528 <code>r = 5;</code> \u9700\u8981\u89e3\u5f15\u7528 <code>*p = 5;</code> \u53ef\u4e3a\u7a7a \u274c\uff08\u5fc5\u987b\u7ed1\u5b9a\u6709\u6548\u5bf9\u8c61\uff09 \u2705\uff08\u53ef\u4ee5 <code>nullptr</code>\uff09 \u53ef\u91cd\u65b0\u6307\u5411 \u274c\uff08\u5f15\u7528\u4e00\u65e6\u7ed1\u5b9a\u5c31\u4e0d\u80fd\u6362\uff09 \u2705\uff08\u53ef\u4ee5\u6539\u53d8\u6307\u5411\u7684\u5730\u5740\uff09 \u5b58\u50a8\u5f00\u9500 \u7f16\u8bd1\u5668\u5b9e\u73b0\u7c7b\u4f3c\u5e38\u91cf\u6307\u9488\uff08\u5e95\u5c42\u6709\u5730\u5740\uff09 \u5c31\u662f\u4e00\u4e2a\u6307\u9488\u53d8\u91cf"},{"location":"Stage_0/0-2-learning-cxx/#lvalue-reference-vs-rvalue-reference","title":"lvalue reference vs rvalue reference","text":"\u7c7b\u578b \u80fd\u7ed1\u5b9a\u5de6\u503c? \u80fd\u7ed1\u5b9a\u53f3\u503c? <code>T&amp;</code> \u2705 \u274c <code>const T&amp;</code> \u2705 \u2705 <code>T&amp;&amp;</code> \u274c\uff08\u9664\u975e <code>std::move</code>\uff09 \u2705 <p>So the lvalue reference if for <code>var</code>, as a more decent way for pointers, while the rvalue reference is to avoid passing by value of large mem vars.  </p> <p>\u66f4\u7cbe\u786e\u7684\u603b\u7ed3:     - T&amp;\uff1a\u7ed1\u5b9a\u5de6\u503c\uff0c\u8bed\u6cd5\u50cf\u503c\u4f20\u9012\uff0c\u8bed\u4e49\u662f\u201c\u5f15\u7528\u540c\u4e00\u4e2a\u5bf9\u8c61\u201d     - T&amp;&amp;\uff1a\u7ed1\u5b9a\u53f3\u503c\uff08\u4e34\u65f6\u5bf9\u8c61\uff09\uff0c\u5141\u8bb8\u201c\u5077\u201d\u8d44\u6e90\uff08\u79fb\u52a8\uff09     - const T&amp;\uff1a\u5de6\u503c\u548c\u53f3\u503c\u90fd\u80fd\u7ed1\u5b9a\uff08\u53ea\u8bfb\uff09\uff0c\u5e38\u7528\u4e8e\u9ad8\u6548\u53ea\u8bfb\u4f20\u53c2     - T&amp;&amp; \u5728\u6a21\u677f\uff1a\u53ef\u80fd\u662f\u53f3\u503c\u5f15\u7528\uff0c\u4e5f\u53ef\u80fd\u662f\u901a\u7528\u5f15\u7528\uff08\u53d6\u51b3\u4e8e\u7c7b\u578b\u63a8\u5bfc\uff09  </p>"},{"location":"Stage_0/0-2-learning-cxx/#static","title":"<code>static</code>","text":"<p>3 levels: 1. Function level: <pre><code>void foo() {\n    static int a = 0;\n    return a++;\n}\n</code></pre></p> <pre><code>If calling the above function multiple times:  \n- 1st: ~~init `a=0`~~ (init when ~~compiling~~ still in runtime, but at the program starting, befor first calling \u9759\u6001\u521d\u59cb\u5316), return `0` and increase `a` to 1.  \n- 2nd: static var will not init again, a is set to 1 after the first call, so this time it will return `1` and increase `a` to `2`.  \n- 3nd: return `2` and increase to `3`.   \n- ...\n\nThe initialisation will be processed when compiling as a is known in compilation. If the `a` in `foo()` is defined by the param of `foo()`, saying `void foo(int v) {static int a = v; return a++;}`, then the static var `a` is not known in compilation and thus it must be initialised in the runtime, i.e. the first time calling.\n</code></pre> <ol> <li>File Level:      In the <code>a.cpp</code> file:  <code>c++     static int counter = 0; //var     static int helper(int, int, int); // func</code>      and in <code>b.cpp</code> file:  <code>c++     static int counter = 0; //var     static int helper(int, int, int); // func</code>     The <code>counter</code> and <code>helper</code> in <code>a.cpp</code> and <code>b.cpp</code> are not the same - this will compiled successfully.     If there is no <code>static</code>, there would be a linker error multiple definition of <code>counter</code>, since all vars are <code>external</code> by default (saying they are visable across files), while static will prevent the visibility.  </li> <li>static class level: <code>c++     #include &lt;iostream&gt;     class MyClass {     public:         static int shared_value; // \u58f0\u660e\uff08\u7c7b\u5185\uff09     };      int MyClass::shared_value = 0; // must have this line. If no def outside class, will raise linked error.       int main() {         MyClass a, b;         a.shared_value = 42; // changed for all classes           std::cout &lt;&lt; b.shared_value &lt;&lt; \"\\n\"; // \u8f93\u51fa 42     }</code></li> </ol>"},{"location":"Stage_0/0-2-learning-cxx/#constexpr","title":"<code>constexpr</code>","text":"<p>The idea is simple: the result of a <code>constexpr</code> function must be known at compile time. However </p> <p>\u8fd0\u884c\u671f\u8c03\u7528\u7684\u672c\u8d28 constexpr \u53ea\u662f\u544a\u8bc9\u7f16\u8bd1\u5668 \u5982\u679c\u53c2\u6570\u662f\u7f16\u8bd1\u671f\u5e38\u91cf\u5c31\u53ef\u4ee5\u5728\u7f16\u8bd1\u671f\u8ba1\u7b97 \u5982\u679c\u53c2\u6570\u4e0d\u662f\u5e38\u91cf\uff0c\u7f16\u8bd1\u5668\u4f1a\u628a\u5b83\u5f53\u4f5c\u666e\u901a\u51fd\u6570\u6267\u884c \u2192 \u5b8c\u5168\u5408\u6cd5  </p> <p>A Deep research of <code>constexpr</code> by <code>.S</code> file and GDB</p>"},{"location":"Stage_0/0-2-learning-cxx/#pure-functions","title":"Pure functions \u7eaf\u51fd\u6570","text":"<ul> <li>Always return same result  </li> <li>no side effect  <ul> <li>No modifying global/external state  </li> <li>No modifying params  </li> <li>No syscall e.g. I/O, exceptions, interrupts...  </li> </ul> </li> </ul>"},{"location":"Stage_0/0-2-learning-cxx/#day-09","title":"Day 09","text":""},{"location":"Stage_0/0-2-learning-cxx/#loop","title":"loop","text":"<p><code>cache</code> is static, so there is no need to compare with i.  </p>"},{"location":"Stage_0/0-2-learning-cxx/#enum-union-trivial","title":"enum, union, trivial","text":""},{"location":"Stage_0/0-2-learning-cxx/#member-functions","title":"member functions","text":""},{"location":"Stage_0/0-2-learning-cxx/#cv","title":"cv","text":""},{"location":"Stage_1/","title":"Stage 1","text":"<p>There are 6 specialisations.  </p>"},{"location":"Stage_1/#ai-complier","title":"AI Complier","text":""},{"location":"Stage_1/2_TinyInfiniTrain/","title":"Tiny Infini Train","text":"<p>A tiny version of Infinitensor for taining.</p> <p>One of the most knotty parts is the start point. Althought the assignment instructs all the needs, task, test dependencies explicitly, it is easy to be lost for a project of dozens of files and thousands of lines.  </p> <p>However, Chatgpt is a good coach. </p>"},{"location":"Stage_1/2_TinyInfiniTrain/#task-1","title":"Task 1","text":"<p>Plus, the assignment for train is much better than Tensor for beginners, as it is so clear and the first task has a template - the task is to complete the missing part in <code>elementwise.cc</code>, while there are many similiar parts done as examples.</p> <p>For the implementation, nothing is special, just copy and paste from one of others and edit the neccessary part. </p> <p>However, for better understanding, it is a pretty good example of how to understand a file in the project.</p>"},{"location":"Stage_1/2_TinyInfiniTrain/#task-1-overview","title":"Task 1 Overview","text":"<p>One should look into the task first.</p> <pre><code>#include \"infini_train/include/autograd/elementwise.h\"\n\n#include \"infini_train/include/dispatcher.h\"\n#include \"infini_train/include/tensor.h\"\n#include &lt;optional&gt;\n\nnamespace infini_train::autograd {\nstd::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; Neg::Forward(const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;input_tensors) {\n    // =================================== \u4f5c\u4e1a ===================================\n    // TODO\uff1a\u901a\u8fc7Dispatcher\u83b7\u53d6\u8bbe\u5907\u4e13\u5c5ekernel\uff0c\u5bf9\u8f93\u5165\u5f20\u91cf\u8fdb\u884c\u53d6\u53cd\u64cd\u4f5c\n    // NOTES: \u4f9d\u8d56test_dispatcher\uff0cNeg kernel\u5b9e\u73b0\u5df2\u7ed9\u51fa\n    // =================================== \u4f5c\u4e1a ===================================\n}\n</code></pre> <p>First we look into the signatures. <code>std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt;</code> means this is a vector of shared ptrs for Tensor, and the argument is the same with just const reference so the argument be borrowed and remains not changed.  </p> <p>Comparing to other operators, for instance, the <code>Reciprocal</code>:  </p> <pre><code>std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; Reciprocal::Forward(const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;input_tensors) {\n    CHECK_EQ(input_tensors.size(), 1);\n    const auto &amp;input = input_tensors[0];\n\n    auto device = input-&gt;GetDevice().Type();\n    auto kernel = Dispatcher::Instance().GetKernel({device, \"ReciprocalForward\"});\n    return {kernel.Call&lt;std::shared_ptr&lt;Tensor&gt;&gt;(input)};\n}\n\nvoid Reciprocal::SetupContext(const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;input_tensors,\n                              const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;) {\n    const auto &amp;input = input_tensors[0];\n    saved_tensors_ = {input};\n}\n</code></pre> <p>The implementation is clear, we first check the dimension of the argument. The reciprocal should recieve one argument only (while the add actually takes two) and so is the neg so we can just following the same steps. Then, we can get the device and the kernel and using the kernel call to return the value. Nothing is special.  </p>"},{"location":"Stage_1/2_TinyInfiniTrain/#class-tensor","title":"Class <code>Tensor</code>","text":"<p>The next step is to look what is a <code>Tensor</code>. Just ctrl click, it redirect me to <code>tensor.h</code>.  </p> <pre><code>class Tensor : public std::enable_shared_from_this&lt;Tensor&gt; {\npublic:\n    // constructors\n    Tensor() = default;\n\n    Tensor(const std::vector&lt;int64_t&gt; &amp;dims, DataType dtype, Device device);\n    Tensor(const std::vector&lt;int64_t&gt; &amp;dims, DataType dtype) : Tensor(dims, dtype, Device(DeviceType::kCPU, 0)) {}\n    Tensor(const Tensor &amp;tensor, size_t offset, const std::vector&lt;int64_t&gt; &amp;dims);\n\n    // member function prototypes.\n    Device GetDevice() const;\n    ...\n\n    // operator overloading\n    std::shared_ptr&lt;Tensor&gt; Equals(float scalar);\n\n    // distribution\n    std::shared_ptr&lt;Tensor&gt; Uniform(float from = 0.0f, float to = 1.0f,\n                                    std::optional&lt;std::mt19937&gt; generator = std::nullopt);\n    ...\n\n    friend std::shared_ptr&lt;Tensor&gt; operator==(const std::shared_ptr&lt;Tensor&gt; &amp;t, float scalar);\n    ...\n\n    void SaveAsNpy(const std::string &amp;path) const;\n    ...\n\nprivate:\n    std::shared_ptr&lt;TensorBuffer&gt; buffer_;\n    size_t offset_ = 0;\n    std::vector&lt;int64_t&gt; dims_;\n    size_t num_elements_ = 0;\n    DataType dtype_;\n\n    // autograd related\npublic:\n...\nprivate:\n...\n};\n</code></pre> <p>The structure is quite clear. It is divided into 2 pieces, while the first half is about it self and the second part is about the autograd related function. </p>"},{"location":"Stage_1/2_TinyInfiniTrain/#signature","title":"Signature","text":"<p>First we look the signature: <code>class Tensor : public std::enable_shared_from_this&lt;Tensor&gt;</code></p> <p>The class is inherent from <code>std::enable_shared_from_this&lt;Tensor&gt;</code>. What does it do? </p> <p>Chatgpt said:</p> <p>\u90a3\u4e48 <code>std::enable_shared_from_this&lt;T&gt;</code> \u662f\u5565\uff1f</p> <p>\u5b83\u662f C++ \u6807\u51c6\u5e93\u63d0\u4f9b\u7684\u4e00\u4e2a\u5c0f\u5de5\u5177\u7c7b\uff0c\u4f5c\u7528\u662f\uff1a \ud83d\udc49 \u8ba9\u4e00\u4e2a\u5bf9\u8c61 \u5728\u81ea\u5df1\u5185\u90e8\u5b89\u5168\u5730\u83b7\u53d6 <code>std::shared_ptr</code> \u6307\u9488\u6307\u5411\u81ea\u5df1\u3002</p> <pre><code>class Tensor {\npublic:\n    std::shared_ptr&lt;Tensor&gt; GetSelf() {\n        return std::shared_ptr&lt;Tensor&gt;(this);  // \u26a0\ufe0f \u9519\u8bef\u7528\u6cd5\uff01\n    }\n};\n</code></pre> <p>\u8fd9\u6837\u5199\u4f1a \u521b\u5efa\u4e00\u4e2a\u65b0\u7684 shared_ptr\uff0c\u5bfc\u81f4\u5f15\u7528\u8ba1\u6570\u9519\u4e71\uff08\u751a\u81f3\u53ef\u80fd double free\uff09\u3002</p> <p>\u5982\u679c <code>Tensor</code> \u7ee7\u627f\u4e86 <code>std::enable_shared_from_this&lt;Tensor&gt;</code>\uff1a</p> <pre><code>class Tensor : public std::enable_shared_from_this&lt;Tensor&gt; {\npublic:\n    std::shared_ptr&lt;Tensor&gt; GetSelf() {\n        return shared_from_this(); // \u2705 \u6b63\u786e\uff0c\u8fd4\u56de\u7ba1\u7406\u81ea\u5df1\u7684 shared_ptr\n    }\n};\n</code></pre> <p>\u73b0\u5728 <code>shared_from_this()</code> \u4f1a\u8fd4\u56de\u4e00\u4e2a\u548c\u5916\u90e8\u76f8\u540c\u63a7\u5236\u5757\u7684 <code>shared_ptr</code>\uff0c\u4e0d\u4f1a\u91cd\u590d\u7ba1\u7406\u5bf9\u8c61\u3002 </p>"},{"location":"Stage_1/2_TinyInfiniTrain/#constructors","title":"Constructors","text":"<p>For the first part, there are 4 constructors. It is called overloading.</p> <pre><code>Tensor() = default; // default\n\nTensor(const std::vector&lt;int64_t&gt; &amp;dims, DataType dtype, Device device); // the most completed version\nTensor(const std::vector&lt;int64_t&gt; &amp;dims, DataType dtype) : Tensor(dims, dtype, Device(DeviceType::kCPU, 0)) {} // delegating constructor, transferring the construction to the most completed version\nTensor(const Tensor &amp;tensor, size_t offset, const std::vector&lt;int64_t&gt; &amp;dims); // ???\n</code></pre> <p>The first 3 versions are easily reading, while the last one seems difficult to understand. The one might infer it is constructing a <code>Tensor</code> from an array rather than vector. But how can we know the exact implementation? It seems that there is no real codes!</p> <p>That's right! It is the same thing for other functions as well. Hopefully, chatgpt helps:</p>"},{"location":"Stage_1/2_TinyInfiniTrain/#how-to-read-the-signature-of-arugument-with-no-name","title":"How to Read the Signature of Arugument with no name?","text":"<p>\u9996\u5148\uff0c\u8fd9\u91cc\u7684\u53c2\u6570\u4ec0\u4e48\u610f\u601d\uff1f\u6211\u9700\u8981\u53ea\u8bfb\u5de6\u503c\u5f15\u7528\uff0c\u8fd9\u4e2a\u6ca1\u95ee\u9898\u3002\u4f46\u662f\u4e3a\u4ec0\u4e48\u7b2c\u4e8c\u4e2a\u53c2\u6570\u6ca1\u6709\u540d\u5b57\uff1f</p> <pre><code>void Reciprocal::SetupContext(const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;input_tensors,\n                              const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;)\n</code></pre> <p>ChatGPT said:</p> <p>\u5728 C++ \u91cc\uff0c\u8fd9\u662f\u4e00\u79cd\u300c\u53c2\u6570\u5360\u4f4d\u300d\u7684\u6280\u5de7\uff1a\u4e0d\u80fd\u53bb\u6389\u53c2\u6570\uff0c\u56e0\u4e3a\u51fd\u6570\u7b7e\u540d\u5fc5\u987b\u5339\u914d\u63a5\u53e3\u3002\u4e0d\u60f3\u7528\u5b83\uff0c\u5c31\u4e0d\u7ed9\u540d\u5b57\uff0c\u907f\u514d\u7f16\u8bd1\u5668\u8b66\u544a\u201c\u672a\u4f7f\u7528\u53d8\u91cf\u201d\u3002</p> <p>That's it! To sync the interfaces with others, there must be 2 argument tough the second one is never used. To avoid the warning of unused variables, we give the type only without name. It is called placeholder parameter.</p>"},{"location":"Stage_1/5_TinyInfiniTensor/","title":"AI Complier","text":""},{"location":"Stage_1/5_TinyInfiniTensor/#hw-1-allocator","title":"HW 1 - Allocator","text":""},{"location":"Stage_1/5_TinyInfiniTensor/#question-understanding","title":"Question Understanding","text":"<pre><code>#pragma once\n#include \"core/runtime.h\"\n#include \"core/tensor.h\"\n#ifdef BUILD_TEST\n#include \"gtest/gtest.h\"\n#endif\n#include &lt;cstddef&gt;\n#include &lt;map&gt;\n#include &lt;unordered_set&gt;\n\nnamespace infini {\n  class Allocator\n  {\n  private:\n    Runtime runtime;\n\n    size_t used;\n\n    size_t peak;\n\n    size_t alignment;\n\n    // pointer to the memory actually allocated\n    void *ptr;\n\n    // =================================== \u4f5c\u4e1a ===================================\n    // TODO\uff1a\u53ef\u80fd\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u6570\u636e\u7ed3\u6784\u6765\u5b58\u50a8free block\uff0c\u4ee5\u4fbf\u4e8e\u7ba1\u7406\u548c\u5408\u5e76\n    // HINT: \u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a map \u6765\u5b58\u50a8 free block\uff0ckey \u4e3a block \u7684\u8d77\u59cb/\u7ed3\u5c3e\u5730\u5740\uff0cvalue \u4e3a block \u7684\u5927\u5c0f\n    // =================================== \u4f5c\u4e1a ===================================\n    std::map&lt;size_t, size_t&gt; free_blocks;\n\n  public:\n    Allocator(Runtime runtime);\n\n    virtual ~Allocator();\n\n    // function: simulate memory allocation\n    // arguments\uff1a\n    //     size: size of memory block to be allocated\n    // return: head address offset of the allocated memory block\n    size_t alloc(size_t size);\n\n    // function: simulate memory free\n    // arguments:\n    //     addr: head address offset of memory block to be free\n    //     size: size of memory block to be freed\n    void free(size_t addr, size_t size);\n\n    // function: perform actual memory allocation\n    // return: pointer to the head address of the allocated memory\n    void *getPtr();\n\n    void info();\n\n  private:\n    // function: memory alignment, rouned up\n    // return: size of the aligned memory block\n    size_t getAlignedSize(size_t size);\n  };\n}\n</code></pre> <p>The allocator is for uniformly manage the ram used in a graph. However, it is just a table while the tensor will still need to allocate the mem from OS.  </p> <p>For the prototype, we need a map. </p> <pre><code>std::map&lt;size_t, size_t&gt; free_blocks;\n</code></pre> <p>The initiation is to allocate the mem statically like early OS, where the allocator needs to create new nodes and merge nodes of free spaces. The codes should be similar to </p> <pre><code>for (; it != free_blocks.end(); it++) {\n    if (it-&gt;second &gt;= size) {\n        offset = it-&gt;first;\n        if (it-&gt;second &gt; size) {\n            free_blocks.emplace(offset+size, it-&gt;second-size);\n        }\n        // Without this line, it will be an undefined behaviour\n        // to test if `it == free_blocks.end()`\n        free_blocks.erase(it);\n        it = free_blocks.begin();\n        break;\n    }\n}\n</code></pre> <p>However, there is big problem - we do not know the initial value. Should we record the allocated mem? It is better to know the perpose. The real project of this tiny teaching model has the allocator as well: </p> <pre><code>size_t LazyAllocator::alloc(size_t size) {\n    // pad the size to the multiple of alignment\n    size = this-&gt;getAlignedSize(size);\n    auto it = this-&gt;freeBlocks.lower_bound(freeBlockInfo{(size_t)0, size});\n\n    size_t retAddr = this-&gt;peak;\n    if (it != this-&gt;freeBlocks.end()) {\n        // found an alvailable free memory block for allocation\n        ...\n    } else {\n        // the allocated memory space is not sufficient for reallocation, it\n        ...\n    }\n\n    return retAddr;\n}\n</code></pre> <p>So the reason is clear - the allocator is to maintain the allocate but freed mem, to reduce the fregments, maintain the peak mem usage and help optimise the graph nodes.</p> <p>Therefore, 1. if there is enough space, allocate the mem in the table with merging 2. else reassign peak / used and add a node in the map</p>"},{"location":"Stage_1/5_TinyInfiniTensor/#implementation","title":"Implementation","text":""},{"location":"Stage_1/5_TinyInfiniTensor/#first-fit-with-olog-n-search","title":"First-fit with \\(O(\\log n)\\) Search","text":"<p>The first intitiation is to use a <code>std::map</code> to store all the pairs of <code>startAddr</code> and <code>size</code> with . For allocation, just do linear scan from the beginning and same for freeing. However, this cost \\(O(\\log n)\\) time for searching, erasing and deleting. Plus, the first-fit strategy can produce more fregments than best fit, which is more commonly used in practice.  </p>"},{"location":"Stage_1/5_TinyInfiniTensor/#best-fit-with-olog-n-search","title":"Best-fit with \\(O(\\log n)\\) Search","text":"<p>It is then very straight forward to implement a balanced tree in the order according to size, and a hashmap with doubly linked list from addresses to values for quicker searching. The prototype should be like: <pre><code>struct BlockInfo {\n    size_t addr;\n    size_t size;\n\n    bool operator&lt;(const BlockInfo &amp;other) const {\n        return (size != other.size) ? (size &lt; other.size) : (addr &lt; other.addr);\n    }\n};\n\n// Balanced tree for free memory blocks, sorted by size and address\nstd::set&lt;BlockInfo&gt; freeBlocks;\n\n// Key: Starting address of the free memory block\n// Value: Size of the block\nstd::unordered_map&lt;size_t, size_t&gt; blockStartToSize;\n</code></pre></p> <p>However, there are 2 problems: 1. when the peak mem must be expanded, we can only do linear search for the address - Add a <code>tailBlock</code> pointer; 2. When freeing the blocks, we cannot find the adjacent blocks. - </p> <p>The last one is a big problem. We must use <code>size</code> and <code>addr</code> to find the block, causing <code>Oo(\\log n)</code> time, which is still good, as eraseing and inserting new blocks will definately take <code>O(\\log n)</code> as well.</p> <p>Another thinking is to insert all the blocks (both used or free) with a dirty tag. However, we only extend the peak when we exceed it - i.e. commonly there must be a lot more used blocks than free blocks, resulting in a much worse time consuming.</p>"},{"location":"Stage_1/5_TinyInfiniTensor/#the-official-implementation","title":"The Official Implementation","text":"<p>One thing reminds me.</p> <p>It is so straightforward only to record the <code>startAddr</code> and <code>size</code>. But why the assignment instruction also mentioned the <code>endAddr</code>?  </p> <p>The reason is, the official implementation gives a balanced tree for blocks in order of size, and 2 hash maps for both start and end addresses! The benefit is:  we can know where is the adjacent blocks if it exist! If there is a block before the newly freed one, its <code>endAddr</code> must be my <code>startAddr</code>, so I can find it from the <code>endAddrToSize</code> hash map and same for the block next. In this way, the searching cost \\(O(1)\\) only with erasing and inserting still \\(O(\\log n)\\) unavoidably.</p>"},{"location":"Stage_1/5_TinyInfiniTensor/#more-researchs","title":"More Researchs","text":"<p>However, it must a fragile structure to maintain 3 datastructes. What is the implementation in pytorch?</p> <p>SHOCKINGLY, no merging at all!</p> <p>Pytorch does not merging free spaces at all. Even if a new block is sufficient to save in two adjacent small blocks, it still requires a new space. Of course this is causing \\(O(1)\\) time only, but that is why we need such a big mem GPU...</p> <p>TBH, it must be better to use some time to merge. Learning rom OS file system, the time consumption for searching and merging index blocks rather than data blocks will not consume too much time.</p>"},{"location":"Stage_1/5_TinyInfiniTensor/#hw-2","title":"HW 2","text":""},{"location":"_Extra/01-constexpr/","title":"A Deep research of <code>constexpr</code> by <code>.S</code> file and GDB","text":""},{"location":"_Extra/01-constexpr/#the-test-file","title":"The Test File","text":"<pre><code>constexpr int square(int x) { return x*x; }\n\nint main() {\n    constexpr int a = square(5);  // 25 is calc at compile time\n    int y = 10;\n    int b = square(y);            // at runtime\n}\n</code></pre>"},{"location":"_Extra/01-constexpr/#are-they-really-computed-at-the-time-they-should-be","title":"Are They Really Computed At the Time They Should Be?","text":"<p>Lets see if above is right. <pre><code>$ g++ -O2 -std=c++17 -S constexpr.cpp -o constexpr.S\n$ cat ./constexpr.S | grep 25\n        movl    $25, %esi\n</code></pre></p> <p>So it is clear that there is a literal put in <code>%esi</code>, where <code>%esi</code> is  </p> <p>what is %esi used for?</p> <p>ChatGPT said:</p> <p>Ah, %esi is one of the general-purpose registers in x86-64 assembly.</p> <p>We do have a variable/argument equals to 25, which cannot be others except a, while for b, it should not be calculated...  </p> <pre><code>$ cat ./constexpr.S | grep 100\n        movl    $100, %esi\n</code></pre> <p>Oops, we have literal 100 at compile time. Why?  </p> <pre><code>$ g++ -O0 -std=c++17 -S constexpr.cpp -o constexpr.S\n$ cat ./constexpr.S | grep 25\n        movl    $25, -12(%rbp)\n        movl    $25, %esi\n$ cat ./constexpr.S | grep 100\n$\n</code></pre> <p>That reason is: the <code>-O0</code> optimisation does constant folding, while <code>-O2</code> does constant folding and constant propagation.      - constant folding: if we know a value of constant, just write the result.     - constant propagation: if we know a value of a var by another var with constant value, we write it in. - Actually <code>-O0</code> parially does this as well  </p> <p>So if we use <code>-O0</code>, we can see why there <code>constexpr</code> can be calc at runtime if the param is not constant, and it should not be propagated  </p> <pre><code>$ cat &lt;&lt; EOF &gt; const-op.cpp\nint main() {\n    int x = 3*3;\n    int y = x + 1;\n    return x;\n}\nEOF\n$ g++ -O0 -S const-op.cpp -o const-op.S\n$ cat const-op.S | grep 10\n$ g++ -O2 -S const-op.cpp -o const-op.S\n$ cat const-op.S | grep 10\n        movl    $10, %eax\n$ \n</code></pre> <p>Back to our example, we should not see literal 100 as it is not computed at compile time.  </p> <pre><code>$ g++ -O2 -std=c++17 -S constexpr.cpp -o constexpr.S\n$ cat ./constexpr.S | grep 25\n        movl    $25, %esi\n$ cat ./constexpr.S | grep 100\n        movl    $100, %esi\n$ g++ -O0 -std=c++17 -S constexpr.cpp -o constexpr.S\n$ cat ./constexpr.S | grep 25\n        movl    $25, -12(%rbp)\n        movl    $25, %esi\n$ cat ./constexpr.S | grep 100\n$\n</code></pre> <p>That's it!</p>"},{"location":"_Extra/01-constexpr/#can-we-use-gdb","title":"Can We Use GDB?","text":"<p>However, reading from <code>.S</code> file are annoying, that's why we have gdb  </p> <pre><code>...\nBreakpoint 1, main () at constexpr.cpp:6\n6           constexpr int a = square(5);  // \u7f16\u8bd1\u671f\u7b97\u51fa 25\n(gdb) p a\n$1 = 0\n(gdb) p b\n$2 = 32767\n(gdb) s\n7           int y = 10;\n(gdb) p a\n$3 = 25\n(gdb) p b\n$4 = 32767\n(gdb) s\n8           int b = square(y);            // \u8fd0\u884c\u671f\u7b97\n(gdb) s\nsquare (x=10) at constexpr.cpp:3\n3       constexpr int square(int x) { return x*x; }\n(gdb) p a\n$5 = {i = {0, 1045149306}, x = 1.2904777690891933e-08, d = 1.2904777690891933e-08}\n(gdb) p b\n$6 = {i = {0, 1068498944}, x = 0.0625, d = 0.0625}\n(gdb) \n</code></pre> <p>We can see that <code>a</code> is set by literal 25 directly, while we must go into the <code>squre()</code> function to compute the outcome for <code>b</code>!</p>"},{"location":"_Extra/01-constexpr/#however-why-a-is-init-as-0","title":"However, why <code>a</code> is init as <code>0</code>?","text":"<ul> <li> The local var should not be set as <code>0</code>, and there seems no corresponding process in <code>.S</code>...</li> </ul>"}]}